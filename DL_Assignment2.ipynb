{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPbmaNjQRRhaDFGmjHC5jA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajuGuguloth/DL-Assignment-2/blob/main/DL_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup and Imports**"
      ],
      "metadata": {
        "id": "y0SOrSNRJaBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n2v0SNew-xa8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Global Configs & Dataset Prep**"
      ],
      "metadata": {
        "id": "7y6OX7J3dw8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Device setup and image config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "IMG_SIZE = (224, 224)\n",
        "CLASS_NAMES = [\"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \"Fungi\",\n",
        "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
        "\n",
        "# Check if dataset is already available\n",
        "if not os.path.exists(\"inaturalist_12K\"):\n",
        "    !wget -q https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip\n",
        "    !unzip -q nature_12K.zip\n",
        "    !rm nature_12K.zip\n",
        "    print(\"Dataset downloaded and extracted.\")\n",
        "else:\n",
        "    print(\"Dataset already exists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmIiRDkbdpd-",
        "outputId": "63f0495f-2f79-47c4-d33c-f1cf2aaad232"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset downloaded and extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***DataLoader Preparation***"
      ],
      "metadata": {
        "id": "sJW7JcZJd1jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom data loading with stratified validation\n",
        "def prepare_dataloaders(train_path, val_path, batch_size):\n",
        "    preprocessing = transforms.Compose([\n",
        "        transforms.Resize(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "    ])\n",
        "\n",
        "    # Load full training dataset\n",
        "    full_train = datasets.ImageFolder(root=train_path, transform=preprocessing)\n",
        "    class_indices = full_train.class_to_idx\n",
        "\n",
        "    # Create balanced validation split\n",
        "    val_indices, train_indices = [], []\n",
        "    for class_label in class_indices.values():\n",
        "        idx = [i for i, (_, y) in enumerate(full_train.samples) if y == class_label]\n",
        "        train_idx, val_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
        "        train_indices.extend(train_idx)\n",
        "        val_indices.extend(val_idx)\n",
        "\n",
        "    train_subset = Subset(full_train, train_indices)\n",
        "    val_subset = Subset(full_train, val_indices)\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(root=val_path, transform=preprocessing)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "metadata": {
        "id": "pRkRuR_gd3ji"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CNN Model (New Style)***"
      ],
      "metadata": {
        "id": "EsFQI-O0d6yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Modular CNN with flexible configuration\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, conv_channels, kernel_sizes, dense_units, dropout_rate, activation, batch_norm):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "\n",
        "        in_channels = 3\n",
        "        for out_channels, k_size in zip(conv_channels, kernel_sizes):\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=k_size))\n",
        "            layers.append(getattr(nn, activation)())\n",
        "            if batch_norm:\n",
        "                layers.append(nn.BatchNorm2d(out_channels))\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        dummy_input = torch.zeros(1, 3, *IMG_SIZE)\n",
        "        dummy_out = self.features(dummy_input)\n",
        "        flatten_dim = dummy_out.view(1, -1).shape[1]\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(flatten_dim, dense_units),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(dense_units, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "JeefJygDd_J_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q1 & Q2: Calculate total computations and parameters manually\n",
        "\n",
        "# Define your CNN architecture parameters\n",
        "input_size = (64, 64, 3)   # height, width, channels (you can change this)\n",
        "num_conv_layers = 5        # Number of conv layers\n",
        "m = 32                     # Filters per conv layer\n",
        "k = 3                      # Kernel size kxk\n",
        "n = 256                    # Neurons in dense layer\n",
        "\n",
        "def compute_total_computations_and_params(input_shape, num_conv_layers, m, k, n, output_classes=10):\n",
        "    h, w, c = input_shape\n",
        "    total_computations = 0\n",
        "    total_params = 0\n",
        "\n",
        "    # Convolution layers\n",
        "    for i in range(num_conv_layers):\n",
        "        output_h = h - k + 1\n",
        "        output_w = w - k + 1\n",
        "        # Each output element does k*k*c multiplications per filter\n",
        "        macs_per_filter = output_h * output_w * (k * k * c)\n",
        "        total_computations += macs_per_filter * m\n",
        "        # Params: weights + bias per filter\n",
        "        params_per_filter = (k * k * c) + 1\n",
        "        total_params += params_per_filter * m\n",
        "\n",
        "        # Update input for next layer\n",
        "        h, w, c = output_h, output_w, m\n",
        "\n",
        "    # Flatten the final feature map\n",
        "    flatten_units = h * w * c\n",
        "\n",
        "    # Dense layer\n",
        "    total_computations += flatten_units * n\n",
        "    total_params += flatten_units * n + n  # weights + bias\n",
        "\n",
        "    # Output layer\n",
        "    total_computations += n * output_classes\n",
        "    total_params += n * output_classes + output_classes\n",
        "\n",
        "    print(\"Total Multiply-Accumulate (MAC) operations:\", f\"{total_computations:,}\")\n",
        "    print(\"Total number of parameters (weights + biases):\", f\"{total_params:,}\")\n",
        "\n",
        "# Run it\n",
        "compute_total_computations_and_params(\n",
        "    input_shape=input_size,\n",
        "    num_conv_layers=num_conv_layers,\n",
        "    m=m,\n",
        "    k=k,\n",
        "    n=n,\n",
        "    output_classes=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8O7Mnjogxad",
        "outputId": "8c9fa0f9-232e-4dd1-a627-6523c6184cfc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Multiply-Accumulate (MAC) operations: 147,167,104\n",
            "Total number of parameters (weights + biases): 23,928,586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Accuracy & Evaluation Utilities***"
      ],
      "metadata": {
        "id": "k62mrIy6eB9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Accuracy calculation\n",
        "def compute_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return round(100 * correct / total, 2)\n"
      ],
      "metadata": {
        "id": "9WqCS47FeL4E"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Function**"
      ],
      "metadata": {
        "id": "hOkaSbfQePsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Model training loop with logging\n",
        "def train_model(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        # Dataloaders\n",
        "        train_loader, val_loader, test_loader = prepare_dataloaders(\n",
        "            train_path=\"inaturalist_12K/train\",\n",
        "            val_path=\"inaturalist_12K/val\",\n",
        "            batch_size=config.batch_size\n",
        "        )\n",
        "\n",
        "        #  Model instantiation\n",
        "        model = CustomCNN(\n",
        "            conv_channels=config.conv_filters,\n",
        "            kernel_sizes=config.kernel_sizes,\n",
        "            dense_units=config.dense_units,\n",
        "            dropout_rate=config.dropout,\n",
        "            activation=config.activation,\n",
        "            batch_norm=config.batch_norm\n",
        "        ).to(device)\n",
        "\n",
        "        #  Loss & Optimizer\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = getattr(optim, config.optimizer)(model.parameters(), lr=config.lr)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "\n",
        "            for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs}\", leave=False):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            val_acc = compute_accuracy(model, val_loader)\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"loss\": running_loss / len(train_loader),\n",
        "                \"val_accuracy\": val_acc\n",
        "            })\n",
        "\n",
        "        # Final test accuracy\n",
        "        test_acc = compute_accuracy(model, test_loader)\n",
        "        wandb.log({\"test_accuracy\": test_acc})\n",
        "        print(f\" Final Test Accuracy: {test_acc}%\")\n"
      ],
      "metadata": {
        "id": "Z9R7IfVYeTez"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Prediction Visualizer (Confusion Matrix + Images)*"
      ],
      "metadata": {
        "id": "GrdWje-oeWBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Visualize predictions on test set\n",
        "def visualize_predictions(model, dataloader, class_names):\n",
        "    model.eval()\n",
        "    images, labels, preds = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            images.extend(inputs.cpu())\n",
        "            labels.extend(targets.cpu())\n",
        "            preds.extend(predicted.cpu())\n",
        "\n",
        "    #  Confusion matrix\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"üìä Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Show few sample predictions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(6):\n",
        "        img = images[i].permute(1, 2, 0) * 0.5 + 0.5  # Unnormalize\n",
        "        true_label = class_names[labels[i]]\n",
        "        pred_label = class_names[preds[i]]\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "42c50ZWNeaVr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***W&B Sweep Setup & Launch***"
      ],
      "metadata": {
        "id": "tPqscBSMecxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define sweep config\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"batch_size\": {\"values\": [32, 64]},\n",
        "        \"epochs\": {\"value\": 5},\n",
        "        \"lr\": {\"min\": 1e-4, \"max\": 1e-2},\n",
        "        \"dropout\": {\"min\": 0.2, \"max\": 0.3},\n",
        "        \"dense_units\": {\"values\": [128, 256]},\n",
        "        \"conv_filters\": {\"values\": [[16, 32, 64], [32, 64, 128]]},\n",
        "        \"kernel_sizes\": {\"values\": [[3, 3, 3], [5, 3, 3]]},\n",
        "        \"optimizer\": {\"values\": [\"Adam\", \"SGD\"]},\n",
        "        \"activation\": {\"values\": [\"ReLU\", \"LeakyReLU\"]},\n",
        "        \"batch_norm\": {\"values\": [True, False]},\n",
        "    }\n",
        "}\n",
        "\n",
        "# Init sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project=\"DA6401_PartA\")\n",
        "\n",
        "# üèÉ‚Äç‚ôÇÔ∏è Start sweep agent (Uncomment to run)\n",
        "# wandb.agent(sweep_id, function=train_model, count=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtgT7deVegvP",
        "outputId": "2e12092f-00bd-4b53-cb42-c5a46824bb7d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: tilapnfk\n",
            "Sweep URL: https://wandb.ai/cs24m036-iit-madras-foundation/DA6401_PartA/sweeps/tilapnfk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bdlNPbNiQ6Em"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}